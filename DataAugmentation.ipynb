{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class bias with data augmentation\n",
    "\n",
    "In this notebook we will try to analyze and reproduce the results shown inside [this paper](https://arxiv.org/pdf/2204.03632.pdf) and find a possible solution for this problem. \n",
    "We will use the tiny-imagenet dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount google drive, load and prepare the data\n",
    "\n",
    "Note that you will need the .zip containing the tiny-imagenet dataset in the root page of your drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "checkpoints = '/content/drive/MyDrive/'\n",
    "if not os.path.exists('tiny-imagenet'):\n",
    "  print(\"Copying to local runtime...\")\n",
    "  shutil.copy(checkpoints + 'tiny-imagenet-200.zip', './tiny-imagenet-200.zip')\n",
    "  print(\"Uncompressing...\")\n",
    "  !unzip 'tiny-imagenet-200.zip'\n",
    "print(\"Data ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import glob\n",
    "import os\n",
    "from shutil import move\n",
    "from os.path import join\n",
    "from os import listdir, rmdir\n",
    "\n",
    "target_folder = './tiny-imagenet-200/val/'\n",
    "test_folder   = './tiny-imagenet-200/testLabel/'\n",
    "\n",
    "os.mkdir(test_folder)\n",
    "val_dict = {}\n",
    "with open('./tiny-imagenet-200/val/val_annotations.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        split_line = line.split('\\t')\n",
    "        val_dict[split_line[0]] = split_line[1]\n",
    "        \n",
    "paths = glob.glob('./tiny-imagenet-200/val/images/*')\n",
    "for path in paths:\n",
    "    file = path.split('/')[-1]\n",
    "    folder = val_dict[file]\n",
    "    if not os.path.exists(target_folder + str(folder)):\n",
    "        os.mkdir(target_folder + str(folder))\n",
    "        os.mkdir(target_folder + str(folder) + '/images')\n",
    "    if not os.path.exists(test_folder + str(folder)):\n",
    "        os.mkdir(test_folder + str(folder))\n",
    "        os.mkdir(test_folder + str(folder) + '/images')\n",
    "        \n",
    "        \n",
    "for path in paths:\n",
    "    file = path.split('/')[-1]\n",
    "    folder = val_dict[file]\n",
    "    if len(glob.glob(target_folder + str(folder) + '/images/*')) <25:\n",
    "        dest = target_folder + str(folder) + '/images/' + str(file)\n",
    "    else:\n",
    "        dest = test_folder + str(folder) + '/images/' + str(file)\n",
    "    move(path, dest)\n",
    "    \n",
    "rmdir('./tiny-imagenet-200/val/images')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single ResNet18\n",
    "\n",
    "This will train a ResNet18 from scratch with 13 different level of crop, then it will plot the accuracy of each class for each level of crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_class = 200\n",
    "crop_range = np.linspace(0.08, 1.0, num=13)\n",
    "epochs = 20\n",
    "\n",
    "def train(net, trainloader, criterion, optimizer):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "          print (f'Epoch [{e+1}/{epochs}], Loss: {loss.item():.6f}')\n",
    "\n",
    "    return running_loss / len(trainloader)\n",
    "\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(n_class))\n",
    "    class_total = list(0. for i in range(n_class))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            c = (predicted == labels).squeeze()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    class_acc = [100 * class_correct[i] / class_total[i] for i in range(n_class)]\n",
    "\n",
    "    return acc, class_acc\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='./tiny-imagenet-200/val/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=14)\n",
    "\n",
    "# Initialize the lists to store the training and testing accuracy\n",
    "lower_bound = []\n",
    "test_acc = []\n",
    "class_acc = []\n",
    "\n",
    "# Train the model for each random crop parameter value\n",
    "for crop in crop_range:\n",
    "    # Update the data augmentation pipeline with the new random crop parameter\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.RandomResizedCrop(64, scale=(crop, 1.0), ratio=(0.8, 1.25)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.ImageFolder(root='./tiny-imagenet-200/train/', transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=14)\n",
    "\n",
    "    model = models.resnet18(pretrained=False, num_classes=n_class)\n",
    "    # Adapt the model to 64x64 images\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "    # Train the model\n",
    "    for e in range(epochs):\n",
    "        train_loss = train(model, trainloader, criterion, optimizer)\n",
    "\n",
    "    # Test the model on the center crop of the test set\n",
    "    acc, class_accCrop = test(model, testloader)\n",
    "\n",
    "    # Save the training and testing accuracy\n",
    "    lower_bound.append(100 * crop)\n",
    "    test_acc.append(acc)\n",
    "    class_acc.append(class_accCrop)\n",
    "\n",
    "    path=  f'/content/drive/My Drive/Colab Notebooks/model/ResNet18/test{str(round(crop, 5))}.pth'\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Plot the result in batch of 10 class each\n",
    "for k in range(20):\n",
    "  start = k * 10\n",
    "  end = start + 10\n",
    "  fig, ax = plt.subplots(figsize=(12,8))\n",
    "  ax.plot(lower_bound, test_acc, '-o', label='Average Test Accuracy', color='blue')\n",
    "  \n",
    "  for i in range(start, end):\n",
    "    ax.plot(lower_bound, [class_acc[j][i] for j in range(len(class_acc))], '-o', label='Class {} Accuracy'.format(i), color=plt.cm.tab10(i%10))\n",
    "\n",
    "  ax.set_xlabel('Lower Bound on Random Crop Parameter (%)', fontsize=14)\n",
    "  ax.set_ylabel('Accuracy (%)', fontsize=14)\n",
    "  ax.set_xlim([0, 100])\n",
    "  ax.set_ylim([0, 100])\n",
    "  ax.legend(loc='lower right', fontsize=8)\n",
    "  ax.grid(True, linestyle='--', alpha=0.5)\n",
    "  ax.set_title('Accuracy vs Lower Bound on Random Crop Parameter', fontsize=16)\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single ResNet34\n",
    "\n",
    "Same as before but using a ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_class = 200\n",
    "crop_range = np.linspace(0.08, 1.0, num=13)\n",
    "epochs = 20\n",
    "\n",
    "def train(net, trainloader, criterion, optimizer):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "          print (f'Epoch [{e+1}/{epochs}], Loss: {loss.item():.6f}')\n",
    "\n",
    "    return running_loss / len(trainloader)\n",
    "\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(n_class))\n",
    "    class_total = list(0. for i in range(n_class))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            c = (predicted == labels).squeeze()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    class_acc = [100 * class_correct[i] / class_total[i] for i in range(n_class)]\n",
    "\n",
    "    return acc, class_acc\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='./tiny-imagenet-200/val/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=14)\n",
    "\n",
    "# Initialize the lists to store the training and testing accuracy\n",
    "lower_bound = []\n",
    "test_acc = []\n",
    "class_acc = []\n",
    "\n",
    "# Train the model for each random crop parameter value\n",
    "for crop in crop_range:\n",
    "    # Update the data augmentation pipeline with the new random crop parameter\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.RandomResizedCrop(64, scale=(crop, 1.0), ratio=(0.8, 1.25)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.ImageFolder(root='./tiny-imagenet-200/train/', transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=14)\n",
    "\n",
    "    model = models.resnet34(pretrained=False, num_classes=n_class)\n",
    "    # Adapt the model to 64x64 images\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "    # Train the model\n",
    "    for e in range(epochs):\n",
    "        train_loss = train(model, trainloader, criterion, optimizer)\n",
    "\n",
    "    # Test the model on the center crop of the test set\n",
    "    acc, class_accCrop = test(model, testloader)\n",
    "\n",
    "    # Save the training and testing accuracy\n",
    "    lower_bound.append(100 * crop)\n",
    "    test_acc.append(acc)\n",
    "    class_acc.append(class_accCrop)\n",
    "\n",
    "    path=  f'/content/drive/My Drive/Colab Notebooks/model/ResNet34/test{str(round(crop, 5))}.pth'\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Plot the result in batch of 10 class each\n",
    "for k in range(20):\n",
    "  start = k * 10\n",
    "  end = start + 10\n",
    "  fig, ax = plt.subplots(figsize=(12,8))\n",
    "  ax.plot(lower_bound, test_acc, '-o', label='Average Test Accuracy', color='blue')\n",
    "  \n",
    "  for i in range(start, end):\n",
    "    ax.plot(lower_bound, [class_acc[j][i] for j in range(len(class_acc))], '-o', label='Class {} Accuracy'.format(i), color=plt.cm.tab10(i%10))\n",
    "\n",
    "  ax.set_xlabel('Lower Bound on Random Crop Parameter (%)', fontsize=14)\n",
    "  ax.set_ylabel('Accuracy (%)', fontsize=14)\n",
    "  ax.set_xlim([0, 100])\n",
    "  ax.set_ylim([0, 100])\n",
    "  ax.legend(loc='lower right', fontsize=8)\n",
    "  ax.grid(True, linestyle='--', alpha=0.5)\n",
    "  ax.set_title('Accuracy vs Lower Bound on Random Crop Parameter', fontsize=16)\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined ResNet18 trained from scratch\n",
    "\n",
    "This is the first version of the combined net. We are combining two separate ResNet18 concatenating the last Linear layer of the two in order to have a single output. It uses a dataset that gives to the combined net two images, one that is original and the other with data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_class = 200\n",
    "crop_range = np.linspace(0.08, 1.0, num=13)\n",
    "epochs = 20\n",
    "\n",
    "checkpoints = '/content/drive/MyDrive/Colab Notebooks/model/CombinedModel/checkpoints/'\n",
    "trainPath = './tiny-imagenet-200/train/'\n",
    "testPath = './tiny-imagenet-200/val/'\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "  \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CombinedResnet18(nn.Module):\n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_classes=200):\n",
    "        self.inplanes = 64\n",
    "        super(CombinedResnet18, self).__init__()\n",
    "\n",
    "        self.resnet1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Identity(),\n",
    "            self._make_layer(block, 64, layers[0]),\n",
    "            self._make_layer(block, 128, layers[1], stride=2),\n",
    "            self._make_layer(block, 256, layers[2], stride=2),\n",
    "            self._make_layer(block, 512, layers[3], stride=2),\n",
    "            nn.AvgPool2d(7, stride=1)\n",
    "        )\n",
    "\n",
    "        self.inplanes = 64\n",
    "\n",
    "        self.resnet2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Identity(),\n",
    "            self._make_layer(block, 64, layers[0]),\n",
    "            self._make_layer(block, 128, layers[1], stride=2),\n",
    "            self._make_layer(block, 256, layers[2], stride=2),\n",
    "            self._make_layer(block, 512, layers[3], stride=2),\n",
    "            nn.AvgPool2d(7, stride=1)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(4096 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.resnet1(x1)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "\n",
    "        x2 = self.resnet2(x2)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "def train(net, trainloader, criterion, optimizer, state=None, checkpoint_path=None, start_epoch=0):\n",
    "    # Load previous training state\n",
    "    if state:\n",
    "        net.load_state_dict(state['net'])\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        start_epoch = state['epoch']\n",
    "        losses = state['losses']\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "      net.train()\n",
    "      running_loss = 0.0\n",
    "      for i, (originalInput, augmentedInput, labels) in enumerate(trainloader, 0):\n",
    "          originalInput = originalInput.to(device)\n",
    "          augmentedInput = augmentedInput.to(device)\n",
    "          labels = labels.to(device)\n",
    "                  \n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outputs = net(originalInput, augmentedInput)\n",
    "\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "\n",
    "          optimizer.step()\n",
    "          running_loss += loss.item()\n",
    "\n",
    "          if i % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}')\n",
    "      \n",
    "      if checkpoint_path:\n",
    "        state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': running_loss}\n",
    "        torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n",
    "        print(\"Checkpoint %d saved\"%(epoch+1))\n",
    "\n",
    "    return running_loss / len(trainloader)\n",
    "\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(n_class))\n",
    "    class_total = list(0. for i in range(n_class))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images, images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            c = (predicted == labels).squeeze()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    class_acc = [100 * class_correct[i] / class_total[i] for i in range(n_class)]\n",
    "\n",
    "    return acc, class_acc\n",
    "\n",
    "class CombinedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transformOriginal, transformAugmented):\n",
    "        self.dataset = dataset\n",
    "        self.transformOriginal = transformOriginal\n",
    "        self.transformAugmented = transformAugmented\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.dataset[index]\n",
    "        img1 = self.transformOriginal(img)\n",
    "        img2 = self.transformAugmented(img)\n",
    "        return img1, img2, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_trainOriginal = transform_train = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root=testPath, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=14)\n",
    "\n",
    "\n",
    "# Initialize the lists to store the training and testing accuracy\n",
    "lower_bound = []\n",
    "test_acc = []\n",
    "class_acc = []\n",
    "\n",
    "# Reload state from a previous checkpoint\n",
    "#state = torch.load(checkpoints + 'checkpoint-19.pkl')\n",
    "state = None\n",
    "\n",
    "# Train the model for each random crop parameter value\n",
    "for crop in crop_range:\n",
    "    # Update the data augmentation pipeline with the new random crop parameter\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.RandomResizedCrop(64, scale=(crop, 1.0), ratio=(0.8, 1.25)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    dataset = torchvision.datasets.ImageFolder(root=trainPath)\n",
    "    trainset = CombinedDataset(dataset=dataset, transformOriginal=transform_trainOriginal, transformAugmented=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=14)\n",
    "\n",
    "    model = CombinedResnet18()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = train(model, trainloader, criterion, optimizer, checkpoint_path=checkpoints, state=state)\n",
    "\n",
    "    # Test the model on the center crop of the test set\n",
    "    acc, class_accCrop = test(model, testloader)\n",
    "\n",
    "    # Save the training and testing accuracy\n",
    "    lower_bound.append(100 * crop)\n",
    "    test_acc.append(acc)\n",
    "    class_acc.append(class_accCrop)\n",
    "\n",
    "    path = f'/content/drive/My Drive/Colab Notebooks/model/CombinedModel/test{str(round(crop, 5))}.pth'\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "    state = None\n",
    "\n",
    "\n",
    "for k in range(20):\n",
    "  start = k * 10\n",
    "  end = start + 10\n",
    "  fig, ax = plt.subplots(figsize=(12,8))\n",
    "  ax.plot(lower_bound, test_acc, '-o', label='Average Test Accuracy', color='blue')\n",
    "  \n",
    "  for i in range(start, end):\n",
    "    ax.plot(lower_bound, [class_acc[j][i] for j in range(len(class_acc))], '-o', label='Class {} Accuracy'.format(i), color=plt.cm.tab10(i%10))\n",
    "\n",
    "  ax.set_xlabel('Lower Bound on Random Crop Parameter (%)', fontsize=14)\n",
    "  ax.set_ylabel('Accuracy (%)', fontsize=14)\n",
    "  ax.set_xlim([0, 100])\n",
    "  ax.set_ylim([0, 100])\n",
    "  ax.legend(loc='lower right', fontsize=8)\n",
    "  ax.grid(True, linestyle='--', alpha=0.5)\n",
    "  ax.set_title('Accuracy vs Lower Bound on Random Crop Parameter', fontsize=16)\n",
    "  plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined ResNet18 pre-trained\n",
    "\n",
    "In this part we created the combined net loading the previous trained ResNet18 and a ResNet18 trained without data augmentation. We then apply only a finetuning to the last common Linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "crop_range = np.linspace(0.08, 1.0, num=13)\n",
    "crop_range = [ 0.46333]\n",
    "n_class = 200\n",
    "epochs = 10\n",
    "\n",
    "checkpoints = '/content/drive/MyDrive/Colab Notebooks/model/CombinedModelPreTrained/checkpoints/'\n",
    "trainPath = './tiny-imagenet-200/train/'\n",
    "testPath = './tiny-imagenet-200/val/'\n",
    "basicModelPath = f'/content/drive/My Drive/Colab Notebooks/model/CombinedModelPreTrained/basicModel.pth'\n",
    "\n",
    "class CombinedResnet18(nn.Module):\n",
    "    def __init__(self, basicModel, augmentedModel, num_classes=200):\n",
    "        super(CombinedResnet18, self).__init__()\n",
    "\n",
    "        self.resnet1 = basicModel\n",
    "        self.resnet1.fc = nn.Identity()\n",
    "\n",
    "        for param in self.resnet1.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "        self.resnet2 = augmentedModel\n",
    "        self.resnet2.fc = nn.Identity()\n",
    "\n",
    "        for param in self.resnet2.parameters():\n",
    "          param.requires_grad = False\n",
    "        \n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.resnet1(x1)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "\n",
    "        x2 = self.resnet2(x2)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CombinedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transformOriginal, transformAugmented):\n",
    "        self.dataset = dataset\n",
    "        self.transformOriginal = transformOriginal\n",
    "        self.transformAugmented = transformAugmented\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.dataset[index]\n",
    "        img1 = self.transformOriginal(img)\n",
    "        img2 = self.transformAugmented(img)\n",
    "        return img1, img2, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "def train(net, trainloader, criterion, optimizer, state=None, checkpoint_path=None, start_epoch=0):\n",
    "    # Load previous training state\n",
    "    if state:\n",
    "        net.load_state_dict(state['net'])\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        start_epoch = state['epoch']\n",
    "        losses = state['losses']\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "      net.train()\n",
    "      running_loss = 0.0\n",
    "      for i, (originalInput, augmentedInput, labels) in enumerate(trainloader, 0):\n",
    "          originalInput = originalInput.to(device)\n",
    "          augmentedInput = augmentedInput.to(device)\n",
    "          labels = labels.to(device)\n",
    "                  \n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outputs = net(originalInput, augmentedInput)\n",
    "\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward()\n",
    "\n",
    "          optimizer.step()\n",
    "          running_loss += loss.item()\n",
    "\n",
    "          if i % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}')\n",
    "      \n",
    "      if checkpoint_path:\n",
    "        state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': running_loss}\n",
    "        torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n",
    "        print(\"Checkpoint %d saved\"%(epoch+1))\n",
    "\n",
    "    return running_loss / len(trainloader)\n",
    "\n",
    "\n",
    "basicModel = models.resnet18(pretrained=False, num_classes=200)\n",
    "\n",
    "basicModel.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "basicModel.maxpool = nn.Identity()\n",
    "\n",
    "basicModel.load_state_dict(torch.load(basicModelPath, map_location=device))\n",
    "\n",
    "\n",
    "transform_trainOriginal = transform_train = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "# Initialize the lists to store the training and testing accuracy\n",
    "lower_bound = []\n",
    "test_acc = []\n",
    "class_acc = []\n",
    "\n",
    "# Reload state from a previous checkpoint\n",
    "#state = torch.load(checkpoints + 'checkpoint-7.pkl')\n",
    "state = None\n",
    "\n",
    "# Train the model for each random crop parameter value\n",
    "for crop in crop_range:\n",
    "    # Update the data augmentation pipeline with the new random crop parameter\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.RandomResizedCrop(64, scale=(crop, 1.0), ratio=(0.8, 1.25)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    dataset = torchvision.datasets.ImageFolder(root=trainPath)\n",
    "    trainset = CombinedDataset(dataset=dataset, transformOriginal=transform_trainOriginal, transformAugmented=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=14)\n",
    "\n",
    "    augmentedModel = models.resnet18(pretrained=False, num_classes=200)\n",
    "    augmentedModel.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    augmentedModel.maxpool = nn.Identity()\n",
    "\n",
    "    augmentedModelPath = f'/content/drive/My Drive/Colab Notebooks/model/ResNet18ImageNet/test{str(round(crop, 5))}.pth'\n",
    "    augmentedModel.load_state_dict(torch.load(augmentedModelPath, map_location=device))\n",
    "\n",
    "    model = CombinedResnet18(basicModel, augmentedModel)\n",
    "    model = model.to(device)  \n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = train(model, trainloader, criterion, optimizer, checkpoint_path=checkpoints, state=state)\n",
    "\n",
    "    lower_bound.append(100 * crop)\n",
    "\n",
    "    path = f'/content/drive/My Drive/Colab Notebooks/model/CombinedModelPreTrained/test{str(round(crop, 5))}.pth'\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "    state = None\n",
    "\n",
    "for k in range(20):\n",
    "  start = k * 10\n",
    "  end = start + 10\n",
    "  fig, ax = plt.subplots(figsize=(12,8))\n",
    "  ax.plot(lower_bound, test_acc, '-o', label='Average Test Accuracy', color='blue')\n",
    "  \n",
    "  for i in range(start, end):\n",
    "    ax.plot(lower_bound, [class_acc[j][i] for j in range(len(class_acc))], '-o', label='Class {} Accuracy'.format(i), color=plt.cm.tab10(i%10))\n",
    "\n",
    "  ax.set_xlabel('Lower Bound on Random Crop Parameter (%)', fontsize=14)\n",
    "  ax.set_ylabel('Accuracy (%)', fontsize=14)\n",
    "  ax.set_xlim([0, 100])\n",
    "  ax.set_ylim([0, 100])\n",
    "  ax.legend(loc='lower right', fontsize=8)\n",
    "  ax.grid(True, linestyle='--', alpha=0.5)\n",
    "  ax.set_title('Accuracy vs Lower Bound on Random Crop Parameter', fontsize=16)\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results\n",
    "\n",
    "These are some indexes that we used to evaluate the results of our experiments.\n",
    "CVaR 5% is the mean of the worst 5% classes,\n",
    "Top 5% is the mean of the best 5% classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "crop_range = np.linspace(0.08, 1.0, num=13)\n",
    "n_class = 200\n",
    "\n",
    "model = models.resnet18(pretrained=False, num_classes=n_class)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model = model.to(device)\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='./tiny-imagenet-200/val/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=14)\n",
    "\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(n_class))\n",
    "    class_total = list(0. for i in range(n_class))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            c = (predicted == labels).squeeze()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    class_acc = [100 * class_correct[i] / class_total[i] for i in range(n_class)]\n",
    "\n",
    "    return acc, class_acc\n",
    "\n",
    "lower_bound = []\n",
    "test_acc = []\n",
    "class_acc = []\n",
    "\n",
    "for crop in crop_range:\n",
    "  path = f'/content/drive/My Drive/Colab Notebooks/model/ResNet18ImageNet/test{str(round(crop, 5))}.pth'\n",
    "  model.load_state_dict(torch.load(path))\n",
    "  model.eval()\n",
    "\n",
    "  acc, class_accCrop = test(model, testloader)\n",
    "\n",
    "  # Save the training and testing accuracy\n",
    "  lower_bound.append(100 * crop)\n",
    "  test_acc.append(acc)\n",
    "  class_acc.append(class_accCrop)\n",
    "\n",
    "\n",
    "data = []\n",
    "tens = torch.Tensor(test_acc)\n",
    "tensClass = torch.Tensor(class_acc)\n",
    "fivePerc = n_class * 0.05\n",
    "\n",
    "for i, crop in enumerate(crop_range):\n",
    "    tmp = []\n",
    "\n",
    "    sortedValues = torch.Tensor(sorted(tensClass[i]))\n",
    "\n",
    "    tmp.append(crop)\n",
    "    tmp.append(tens[i])\n",
    "    tmp.append(tensClass[i].var())\n",
    "    tmp.append(tensClass[i].std())\n",
    "    tmp.append(sortedValues[:int(fivePerc)].mean())\n",
    "    tmp.append(sortedValues[-int(fivePerc):].mean())\n",
    "    data.append(tmp)\n",
    "\n",
    "\n",
    "print(tabulate(data, headers=[\"Crop %\", \"Mean %\", \"Var\", \"Std\", \"CVaR 5%\", \"Top 5%\"], tablefmt=\"psql\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "crop_range = np.linspace(0.08, 1.0, num=13)\n",
    "n_class = 200\n",
    "\n",
    "model = models.resnet34(pretrained=False, num_classes=n_class)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model = model.to(device)\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='./tiny-imagenet-200/val/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=14)\n",
    "\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(n_class))\n",
    "    class_total = list(0. for i in range(n_class))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            c = (predicted == labels).squeeze()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    class_acc = [100 * class_correct[i] / class_total[i] for i in range(n_class)]\n",
    "\n",
    "    return acc, class_acc\n",
    "\n",
    "lower_bound = []\n",
    "test_acc = []\n",
    "class_acc = []\n",
    "\n",
    "for crop in crop_range:\n",
    "  path = f'/content/drive/My Drive/Colab Notebooks/model/ResNet34/test{str(round(crop, 5))}.pth'\n",
    "  model.load_state_dict(torch.load(path))\n",
    "  model.eval()\n",
    "\n",
    "  acc, class_accCrop = test(model, testloader)\n",
    "\n",
    "  # Save the training and testing accuracy\n",
    "  lower_bound.append(100 * crop)\n",
    "  test_acc.append(acc)\n",
    "  class_acc.append(class_accCrop)\n",
    "\n",
    "\n",
    "data = []\n",
    "tens = torch.Tensor(test_acc)\n",
    "tensClass = torch.Tensor(class_acc)\n",
    "fivePerc = n_class * 0.05\n",
    "\n",
    "for i, crop in enumerate(crop_range):\n",
    "    tmp = []\n",
    "\n",
    "    sortedValues = torch.Tensor(sorted(tensClass[i]))\n",
    "\n",
    "    tmp.append(crop)\n",
    "    tmp.append(tens[i])\n",
    "    tmp.append(tensClass[i].var())\n",
    "    tmp.append(tensClass[i].std())\n",
    "    tmp.append(sortedValues[:int(fivePerc)].mean())\n",
    "    tmp.append(sortedValues[-int(fivePerc):].mean())\n",
    "    data.append(tmp)\n",
    "\n",
    "\n",
    "print(tabulate(data, headers=[\"Crop %\", \"Mean %\", \"Var\", \"Std\", \"CVaR 5%\", \"Top 5%\"], tablefmt=\"psql\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined ResNet18 trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "crop_range = np.linspace(0.08, 1.0, num=13)\n",
    "n_class = 200\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "  \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CombinedResnet18(nn.Module):\n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_classes=200):\n",
    "        self.inplanes = 64\n",
    "        super(CombinedResnet18, self).__init__()\n",
    "\n",
    "        self.resnet1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Identity(),\n",
    "            self._make_layer(block, 64, layers[0]),\n",
    "            self._make_layer(block, 128, layers[1], stride=2),\n",
    "            self._make_layer(block, 256, layers[2], stride=2),\n",
    "            self._make_layer(block, 512, layers[3], stride=2),\n",
    "            nn.AvgPool2d(7, stride=1)\n",
    "        )\n",
    "\n",
    "        self.inplanes = 64\n",
    "\n",
    "        self.resnet2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Identity(),\n",
    "            self._make_layer(block, 64, layers[0]),\n",
    "            self._make_layer(block, 128, layers[1], stride=2),\n",
    "            self._make_layer(block, 256, layers[2], stride=2),\n",
    "            self._make_layer(block, 512, layers[3], stride=2),\n",
    "            nn.AvgPool2d(7, stride=1)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(4096 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.resnet1(x1)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "\n",
    "        x2 = self.resnet2(x2)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CombinedResnet18()\n",
    "model = model.to(device)\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='./tiny-imagenet-200/val/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=14)\n",
    "\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(n_class))\n",
    "    class_total = list(0. for i in range(n_class))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images, images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            c = (predicted == labels).squeeze()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    class_acc = [100 * class_correct[i] / class_total[i] for i in range(n_class)]\n",
    "\n",
    "    return acc, class_acc\n",
    "\n",
    "lower_bound = []\n",
    "test_acc = []\n",
    "class_acc = []\n",
    "\n",
    "for crop in crop_range:\n",
    "  path = f'/content/drive/My Drive/Colab Notebooks/model/CombinedModel/test{str(round(crop, 5))}.pth'\n",
    "  model.load_state_dict(torch.load(path, map_location=device))\n",
    "  model.eval()\n",
    "\n",
    "  acc, class_accCrop = test(model, testloader)\n",
    "\n",
    "  # Save the training and testing accuracy\n",
    "  lower_bound.append(100 * crop)\n",
    "  test_acc.append(acc)\n",
    "  class_acc.append(class_accCrop)\n",
    "\n",
    "data = []\n",
    "tens = torch.Tensor(test_acc)\n",
    "tensClass = torch.Tensor(class_acc)\n",
    "fivePerc = n_class * 0.05\n",
    "\n",
    "for i, crop in enumerate(crop_range):\n",
    "    tmp = []\n",
    "\n",
    "    sortedValues = torch.Tensor(sorted(tensClass[i]))\n",
    "\n",
    "    tmp.append(crop)\n",
    "    tmp.append(tens[i])\n",
    "    tmp.append(tensClass[i].var())\n",
    "    tmp.append(tensClass[i].std())\n",
    "    tmp.append(sortedValues[:int(fivePerc)].mean())\n",
    "    tmp.append(sortedValues[-int(fivePerc):].mean())\n",
    "    data.append(tmp)\n",
    "\n",
    "\n",
    "print(tabulate(data, headers=[\"Crop %\", \"Mean %\", \"Var\", \"Std\", \"CVaR 5%\", \"Top 5%\"], tablefmt=\"psql\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined ResNet18 pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "crop_range = np.linspace(0.08, 1.0, num=13)\n",
    "n_class = 200\n",
    "\n",
    "class CombinedResnet18(nn.Module):\n",
    "    def __init__(self, basicModel, augmentedModel, num_classes=200):\n",
    "        super(CombinedResnet18, self).__init__()\n",
    "\n",
    "        self.resnet1 = basicModel\n",
    "        self.resnet1.fc = nn.Identity()\n",
    "\n",
    "        for param in self.resnet1.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "        self.resnet2 = augmentedModel\n",
    "        self.resnet2.fc = nn.Identity()\n",
    "\n",
    "        for param in self.resnet2.parameters():\n",
    "          param.requires_grad = False\n",
    "        \n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.resnet1(x1)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "\n",
    "        x2 = self.resnet2(x2)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "basicModel = models.resnet18(pretrained=False, num_classes=200)\n",
    "basicModel.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "basicModel.maxpool = nn.Identity()\n",
    "\n",
    "augmentedModel = models.resnet18(pretrained=False, num_classes=200)\n",
    "augmentedModel.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "augmentedModel.maxpool = nn.Identity()\n",
    "\n",
    "model = CombinedResnet18(basicModel, augmentedModel)\n",
    "model = model.to(device)\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='./tiny-imagenet-200/val/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=14)\n",
    "\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(n_class))\n",
    "    class_total = list(0. for i in range(n_class))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images, images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            c = (predicted == labels).squeeze()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    class_acc = [100 * class_correct[i] / class_total[i] for i in range(n_class)]\n",
    "\n",
    "    return acc, class_acc\n",
    "\n",
    "lower_bound = []\n",
    "test_acc = []\n",
    "class_acc = []\n",
    "data = []\n",
    "\n",
    "for crop in crop_range:\n",
    "  path = f'/content/drive/My Drive/Colab Notebooks/model/CombinedModelPreTrained/test{str(round(crop, 5))}.pth'\n",
    "  model.load_state_dict(torch.load(path, map_location=device))\n",
    "  model.eval()\n",
    "\n",
    "  acc, class_accCrop = test(model, testloader)\n",
    "\n",
    "  # Save the training and testing accuracy\n",
    "  lower_bound.append(100 * crop)\n",
    "  test_acc.append(acc)\n",
    "  class_acc.append(class_accCrop)\n",
    "\n",
    "data = []\n",
    "tens = torch.Tensor(test_acc)\n",
    "tensClass = torch.Tensor(class_acc)\n",
    "fivePerc = n_class * 0.05\n",
    "\n",
    "for i, crop in enumerate(crop_range):\n",
    "    tmp = []\n",
    "\n",
    "    sortedValues = torch.Tensor(sorted(tensClass[i]))\n",
    "\n",
    "    tmp.append(crop)\n",
    "    tmp.append(tens[i])\n",
    "    tmp.append(tensClass[i].var())\n",
    "    tmp.append(tensClass[i].std())\n",
    "    tmp.append(sortedValues[:int(fivePerc)].mean())\n",
    "    tmp.append(sortedValues[-int(fivePerc):].mean())\n",
    "\n",
    "    data.append(tmp)\n",
    "\n",
    "\n",
    "print(tabulate(data, headers=[\"Crop %\", \"Mean %\", \"Var\", \"Std\", \"CVaR 5%\", \"Top 5%\"], tablefmt=\"psql\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
